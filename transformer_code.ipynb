{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2a7f67-22f7-49de-a9c1-ba08d6fe3793",
   "metadata": {},
   "source": [
    "# Transformer From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c5906-0341-43af-a94d-139a2e72b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f43875-065a-4a69-9d5f-b3ddf8e9ff47",
   "metadata": {},
   "source": [
    "## Create Tokenizer & Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdcf0f-b776-4b0e-9763-b5c1949b4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'english-german-both.pkl'\n",
    "\n",
    "with open(filename, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fe69a-130e-4559-b120-7402cc653e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"English: '{data[0,0]}'\")\n",
    "print(f\"German: '{data[0, 1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2756a-4445-4419-ae8f-0c33ea8c6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Defining a set that will contain every word present in each language.\n",
    "en_vocab_set = set({\"<sos>\", \"<eos>\"})\n",
    "ge_vocab_set = set({\"<sos>\", \"<eos>\"})\n",
    "\n",
    "# Creating the set\n",
    "for i in range(len(data)):\n",
    "    en_tokens = word_tokenize(data[i, 0])\n",
    "    ge_tokens = word_tokenize(data[i, 1])\n",
    "\n",
    "    for tok in en_tokens:\n",
    "        en_vocab_set.add(tok)\n",
    "    for tok in ge_tokens:\n",
    "        ge_vocab_set.add(tok)\n",
    "\n",
    "# Defining a mapping from token to integer\n",
    "en_vocab = {\"<pad>\": 0}\n",
    "en_vocab_reversed = {0: \"<pad>\"}\n",
    "ge_vocab = {\"<pad>\": 0}\n",
    "ge_vocab_reversed = {0: \"<pad>\"}\n",
    "\n",
    "for i, word in enumerate(en_vocab_set):\n",
    "    en_vocab[word] = i+1\n",
    "    en_vocab_reversed[i+1] = word\n",
    "\n",
    "for i, word in enumerate(ge_vocab_set):\n",
    "    ge_vocab[word] = i+1\n",
    "    ge_vocab_reversed[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968ed95-6c56-4eeb-8bea-3b00abb0d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tok_len = 0\n",
    "processed_data_en = []\n",
    "processed_data_ge = []\n",
    "for ex in data:\n",
    "    en_sentence = [\"<sos>\"] + word_tokenize(ex[0]) + [\"<eos>\"]\n",
    "    ge_sentence = [\"<sos>\"] + word_tokenize(ex[1]) + [\"<eos>\"]\n",
    "\n",
    "    en_sent_ints = [en_vocab[tok] for tok in en_sentence]\n",
    "    ge_sent_ints = [ge_vocab[tok] for tok in ge_sentence]\n",
    "\n",
    "    processed_data_en.append(torch.tensor(en_sent_ints))\n",
    "    processed_data_ge.append(torch.tensor(ge_sent_ints))\n",
    "    \n",
    "    max_tok_len = max(max_tok_len, len(en_sent_ints), len(ge_sent_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead6364-03bc-48b4-9bde-8aaa0021f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data_en = []\n",
    "padded_data_ge = []\n",
    "\n",
    "for ex_en, ex_ge in zip(processed_data_en, processed_data_ge):\n",
    "    padded_data_en.append(F.pad(ex_en, (0, max_tok_len-len(ex_en))))\n",
    "    padded_data_ge.append(F.pad(ex_ge, (0, max_tok_len-len(ex_ge))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b69ff-b645-4cc3-a170-31c10675dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 745\n",
    "\n",
    "print('--- English ---')\n",
    "print(padded_data_en[idx])\n",
    "print([en_vocab_reversed[val.item()] for val in padded_data_en[idx]])\n",
    "\n",
    "print()\n",
    "print('--- German ---')\n",
    "\n",
    "print(padded_data_ge[idx])\n",
    "print([ge_vocab_reversed[val.item()] for val in padded_data_ge[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0980b-5de0-4a70-93d8-89ce425de8f9",
   "metadata": {},
   "source": [
    "## Transformer Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c7728-f170-4fad-8eb8-6c11ab7e879c",
   "metadata": {},
   "source": [
    "### Input & Output Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3501a-d164-4e05-ac1c-c5b34b7ac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, dmodel):\n",
    "        super().__init__()\n",
    "        self.embedder = nn.Embedding(vocab_size, dmodel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedder(x)\n",
    "\n",
    "\n",
    "class OutputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, dmodel):\n",
    "        super().__init__()\n",
    "        self.embedder = nn.Embedding(vocab_size, dmodel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11815a69-7980-4d43-8711-173fa0d6f3fb",
   "metadata": {},
   "source": [
    "### Scaled Dot Product Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af357f0a-0815-4ae5-b6aa-a478cbf08e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotAttention(nn.Module):\n",
    "    def __init__(self, dmodel, dk):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Linear(dmodel, dk)\n",
    "        self.Wk = nn.Linear(dmodel, dk)\n",
    "        self.Wv = nn.Linear(dmodel, dk)\n",
    "\n",
    "        self.dk = dk\n",
    "\n",
    "    def apply_masks(self, query_key_matrix, padding_mask, causal_mask):\n",
    "        masked_query_key_matrix = torch.where(padding_mask == 1, \n",
    "                                              torch.full_like(query_key_matrix, -1e9), \n",
    "                                              query_key_matrix)\n",
    "\n",
    "        if causal_mask is not None:\n",
    "            masked_query_key_matrix = torch.where(causal_mask == 1, \n",
    "                                                  torch.full_like(masked_query_key_matrix, -1e9), \n",
    "                                                  masked_query_key_matrix)\n",
    "\n",
    "        return masked_query_key_matrix\n",
    "\n",
    "    def forward(self, Qx, Kx, Vx, padding_mask, causal_mask=None):\n",
    "        Q = self.Wq(Qx)\n",
    "        K = self.Wk(Kx)\n",
    "        V = self.Wv(Vx)\n",
    "        \n",
    "        query_key_matrix = torch.matmul(Q, torch.transpose(K, 1, 2)) / np.sqrt(self.dk)\n",
    "        masked_query_key_matrix = self.apply_masks(query_key_matrix, padding_mask, causal_mask)\n",
    "        key_query_softmax = F.softmax(masked_query_key_matrix, dim=-1)\n",
    "\n",
    "        return torch.matmul(key_query_softmax, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64181143-26c7-40ed-ae58-545ec880230f",
   "metadata": {},
   "source": [
    "### Multi Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5c6bf-4c28-4b68-bd45-144ec9a6d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk):\n",
    "        super().__init__()\n",
    "        self.attention_heads = nn.ModuleList([ScaledDotAttention(dmodel, dk) for i in range(num_heads)])\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.Wo = nn.Linear(self.num_heads * dk, dmodel)\n",
    "\n",
    "    def forward(self, Qx, Kx, Vx, padding_mask, causal_mask=None):\n",
    "\n",
    "        attention_results = [self.attention_heads[i](Qx, Kx, Vx, padding_mask, causal_mask) for i in range(self.num_heads)]\n",
    "        concat_results = torch.cat(attention_results, dim=2)\n",
    "        \n",
    "        return self.Wo(concat_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8995b7-5785-453c-9718-6d0a3bf14394",
   "metadata": {},
   "source": [
    "### Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12282ef6-f85a-4bab-acb0-543c02f2ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dmodel, dff):\n",
    "        super().__init__()\n",
    "        self.inner_linear = nn.Linear(dmodel, dff)\n",
    "        self.outer_linear = nn.Linear(dff, dmodel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.outer_linear(F.relu(self.inner_linear(x)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72354bb-7528-49d9-94c5-7e11e8a85812",
   "metadata": {},
   "source": [
    "### Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41080a0b-400e-40c1-9eba-fe2458bd0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, dmodel):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(dmodel)\n",
    "\n",
    "    def forward(self, x, skipped_x):\n",
    "        return self.layer_norm(x + skipped_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ffa9e-c5bb-4260-83a1-951c906afaea",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2318acc-8359-44c1-80ef-45956cf4cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dmodel):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, tok_len, dmodel = x.shape # (B x num_tok x dmodel)\n",
    "        positional_encodings = torch.zeros_like(x)\n",
    "\n",
    "        for pos in range(tok_len):\n",
    "            for i in range(dmodel):\n",
    "                if i % 2 == 0:\n",
    "                    positional_encodings[:, pos, i] = np.sin(pos / (10000 ** (2*i/ dmodel)))\n",
    "                else:\n",
    "                    positional_encodings[:, pos, i] = np.cos(pos / (10000 ** (2*i/ dmodel)))\n",
    "\n",
    "        return x + positional_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62c587-94aa-48c4-8c4b-8173c833ae86",
   "metadata": {},
   "source": [
    "### Causal Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1773cda-0f35-437a-b23f-231af5861cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(batch_size, max_tok_len):\n",
    "    matrix = torch.ones((max_tok_len, max_tok_len))\n",
    "    matrix = torch.triu(matrix) - torch.eye(max_tok_len)\n",
    "    return matrix.unsqueeze(0).repeat(batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fafbe1-085a-497d-a4e4-39de16a4fea8",
   "metadata": {},
   "source": [
    "### Padding Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90c0f2-ce77-468d-80bb-09548a1dd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x, max_tok_len):\n",
    "    batch_size = x.shape[0]\n",
    "    \n",
    "    mask = (x == 0)\n",
    "    expanded_mask = mask.unsqueeze(1).expand(batch_size, max_tok_len, max_tok_len)\n",
    "    full_mask = expanded_mask | torch.transpose(expanded_mask, 1, 2)\n",
    "\n",
    "    return full_mask.float()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c0eb4-08bd-44fd-b9e7-d8f26137f3ce",
   "metadata": {},
   "source": [
    "## Building Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf5e12-9688-436e-8792-68d99f357892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dff):\n",
    "        super().__init__()\n",
    "        self.multi_headed_attention = MultiHeadedAttention(num_heads, dmodel, dk)\n",
    "        self.add_norm_1 = AddAndNorm(dmodel)\n",
    "        self.add_norm_2 = AddAndNorm(dmodel)\n",
    "        self.feed_forward = FeedForward(dmodel, dff)\n",
    "\n",
    "    def forward(self, x, padding_mask):\n",
    "        x1 = self.multi_headed_attention(x, x, x, padding_mask)\n",
    "        x1 = self.add_norm_1(x1, x)\n",
    "\n",
    "        x2 = self.feed_forward(x1)\n",
    "        x2 = self.add_norm_2(x2, x1)\n",
    "\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f77e3-2446-4dbb-9855-c2a7e0fdf9a6",
   "metadata": {},
   "source": [
    "## Building Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99f1d4-a1c9-4531-8b54-e72ccd20da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_heads, dmodel, dk, dff):\n",
    "        super().__init__()\n",
    "        self.masked_multi_headed_attention = MultiHeadedAttention(num_heads, dmodel, dk)\n",
    "        self.multi_headed_attention = MultiHeadedAttention(num_heads, dmodel, dk)\n",
    "        self.add_norm_1 = AddAndNorm(dmodel)\n",
    "        self.add_norm_2 = AddAndNorm(dmodel)\n",
    "        self.add_norm_3 = AddAndNorm(dmodel)\n",
    "        self.feed_forward = FeedForward(dmodel, dff)\n",
    "        \n",
    "\n",
    "    def forward(self, dec_input, enc_out, padding_mask, causal_mask):\n",
    "        x1 = self.masked_multi_headed_attention(dec_input, dec_input, dec_input, padding_mask, causal_mask)\n",
    "        x1 = self.add_norm_1(x1, dec_input)\n",
    "\n",
    "        x2 = self.multi_headed_attention(x1, enc_out, enc_out, padding_mask)\n",
    "        x2 = self.add_norm_2(x2, x1)\n",
    "\n",
    "        x3 = self.feed_forward(x2)\n",
    "        x3 = self.add_norm_3(x3, x2)\n",
    "\n",
    "        return x3      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5b9ed-28a2-4aed-88d2-65cecc9af540",
   "metadata": {},
   "source": [
    "## Building Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b026e2-d320-47da-bace-84e57c3d2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dk, num_heads, dmodel, dff, num_blocks, src_vocab_size, tgt_vocab_size, max_tok_len):\n",
    "        super().__init__()\n",
    "        self.dk = dk\n",
    "        self.num_heads = num_heads\n",
    "        self.dmodel = dmodel\n",
    "        self.dff = dff\n",
    "        self.num_blocks = num_blocks\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "        self.max_tok_len = max_tok_len\n",
    "        \n",
    "        self.create_layers()\n",
    "\n",
    "    \n",
    "    def create_layers(self):\n",
    "        self.positional_encoding = PositionalEncoding(self.dmodel)\n",
    "        self.encoder_embedding = InputEmbedding(self.src_vocab_size, self.dmodel)\n",
    "        self.decoder_embedding = OutputEmbedding(self.tgt_vocab_size, self.dmodel)\n",
    "        \n",
    "        self.encoders = nn.ModuleList([Encoder(self.num_heads, self.dmodel, self.dk, self.dff) for _ in range(self.num_blocks)])\n",
    "        self.decoders = nn.ModuleList([Decoder(self.num_heads, self.dmodel, self.dk, self.dff) for _ in range(self.num_blocks)])\n",
    "\n",
    "        self.final_linear = nn.Linear(self.dmodel, self.tgt_vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, enc_input, dec_input, padding_mask, causal_mask):\n",
    "        encoder_inputs = self.positional_encoding(self.encoder_embedding(enc_input))\n",
    "\n",
    "        for i in range(self.num_blocks):\n",
    "            encoder_inputs = self.encoders[i](encoder_inputs, padding_mask)\n",
    "\n",
    "        encoder_outputs = encoder_inputs\n",
    "\n",
    "        decoder_inputs = self.positional_encoding(self.decoder_embedding(dec_input))\n",
    "        for i in range(self.num_blocks):\n",
    "            decoder_inputs = self.decoders[i](decoder_inputs, encoder_outputs, padding_mask, causal_mask)\n",
    "\n",
    "        linear_proj = self.final_linear(decoder_inputs)\n",
    "        return linear_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ec102-ed21-4f77-aef9-0c1a1d71718d",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09156e45-de57-4b1d-9073-d1656aaaceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84304385-c5c9-4640-a82a-f966ba776723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(torch.stack(padded_data_en), torch.stack(padded_data_ge))\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0476d-2365-4ca7-b9f2-c11bc0da5a83",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee45901-0ee8-4b9a-a449-eac9c90eddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"dk\": 64,\n",
    "    \"num_heads\": 8,\n",
    "    \"dmodel\": 512,\n",
    "    \"dff\": 2048,\n",
    "    \"num_blocks\": 1,\n",
    "    \"src_vocab_size\": len(en_vocab),\n",
    "    \"tgt_vocab_size\": len(ge_vocab),\n",
    "    \"max_tok_len\": max_tok_len - 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215255d-cb98-4895-b969-9db79d4e1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Transformer(**configs).to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "causal_mask = create_causal_mask(batch_size, max_tok_len-1).to(device)\n",
    "losses = []\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        src, trg = batch\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        padding_mask = create_padding_mask(src[:,1:], configs[\"max_tok_len\"]).to(device)\n",
    "\n",
    "        output = model(src[:,1:], trg[:,:-1], padding_mask, causal_mask)\n",
    "        loss = loss_fn(output.transpose(1, 2), trg[:,1:])\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch {epoch} Batch {batch_idx} Loss {loss.item()}')\n",
    "\n",
    "    losses.append(total_loss / len(train_dataloader))\n",
    "    print(f'Epoch {epoch} Average Loss {total_loss / len(train_dataloader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
